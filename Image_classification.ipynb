{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import cv2 as cv\n",
    "from imageai.Detection import ObjectDetection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move images into train, test, validate folders with subfolders for classes\n",
    "test_ratio = .15\n",
    "SPLIT_DATA = False # switch if need to divide out data\n",
    "if SPLIT_DATA:\n",
    "    for label in ['sidewalk', 'no_sidewalk']:\n",
    "        %cd ./$label\n",
    "        listing = os.popen('ls').read().strip().split(sep='\\n')\n",
    "        random.shuffle(listing) #inplace\n",
    "        im_count = len(listing)\n",
    "        test_size=val_size = math.ceil(test_ratio*im_count)\n",
    "        train_size = im_count - (test_size + val_size)\n",
    "        subfolders = ['train', 'test', 'vdate']\n",
    "        for subfolder in subfolders:\n",
    "            os.makedirs(os.path.join(os.path.dirname(os.getcwd()), subfolder, label))\n",
    "        for item in range(0, train_size):\n",
    "            moved = listing.pop()\n",
    "            !mv $moved ../train/$label/$moved\n",
    "        for item in range(0, test_size):\n",
    "            moved = listing.pop()\n",
    "            !mv $moved ../test/$label/$moved\n",
    "        for item in range(0, val_size):\n",
    "            moved = listing.pop()\n",
    "            !mv $moved ../vdate/$label/$moved\n",
    "        %cd ..\n",
    "        !rmdir ./$label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for data loading and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg_params={'rescale': 1./255}\n",
    "augmentation_params = {'rotation_range': 30,\n",
    "                        'zoom_range': 0.15,\n",
    "                         'width_shift_range': 0.2,\n",
    "                         'height_shift_range': 0.2,\n",
    "                         'shear_range': 0.15,\n",
    "                         'fill_mode': 'nearest',\n",
    "                         'horizontal_flip': True}\n",
    "datagen_params = {batch_size: 32,\n",
    "                  target_size: (256,256),\n",
    "                  color_mode: 'rgb', \n",
    "                  class_mode: 'binary'}\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(**idg_params)\n",
    "train_augmented_datagen = ImageDataGenerator(\n",
    "    **idg_params,\n",
    "    **augmentation_params)\n",
    "test_datagen = ImageDataGenerator(**idg_params)\n",
    "vdate_datagen = ImageDataGenerator(**idg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'./train/',  # This is the source directory for training images\n",
    "        **datagen_params)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r'./test/',\n",
    "        **datagen_params)\n",
    "vdate_generator = vdate_datagen.flow_from_directory(\n",
    "        r'./vdate/',\n",
    "        **datagen_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-71159338d1d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "#generator based caluculations\n",
    "input_shape = train_generator.next()[0].shape[1:]\n",
    "total_train_samples = train_generator.n\n",
    "total_vdate_samples = vdate_generator.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-459a7115a81a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m conv_model.add(Conv2D(32, kernel_size=(3, 3),\n\u001b[0;32m      3\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                  input_shape=input_shape))\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "conv_model = tf.keras.models.Sequential()\n",
    "conv_model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "conv_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "conv_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "conv_model.add(Dropout(0.20))\n",
    "conv_model.add(Flatten())\n",
    "conv_model.add(Dense(128, activation='relu'))\n",
    "conv_model.add(Dropout(0.2))\n",
    "conv_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "conv_model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_history = conv_model.fit_generator(\n",
    "        train_augmented_generator, \n",
    "        steps_per_epoch=int(total_train_samples/batch_size),  \n",
    "        epochs=n_epochs,\n",
    "        verbose=1,\n",
    "        validation_data=vdate_datagen\n",
    "        validation_steps=int(total_vdate_samples/batch_size),\n",
    "        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "n_epochs_range = np.arange(0, n_epochs)\n",
    "plt.style.use(\"ggplot\")\n",
    "fig, ax = plt.figure()\n",
    "ax.plot(n_epochs_range, conv_history.history[\"loss\"], label=\"train_loss\")\n",
    "ax.plot(n_epochs_range, conv_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "ax.plot(n_epochs_range, conv_history.history[\"acc\"], label=\"train_acc\")\n",
    "ax.plot(n_epochs_range, conv_history.history[\"val_acc\"], label=\"val_acc\")\n",
    "\n",
    "ax.set_title(\"Training Loss and Accuracy on Dataset\")\n",
    "ax.set_xlabel(\"Epoch #\")\n",
    "ax.set_ylabel(\"Loss/Accuracy\")\n",
    "ax.set_legend(loc=\"lower left\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection via Transfer Learning\n",
    "This will use a pretrained model as the basis for a nn that identifies the part of an image file that contains the sidewalk object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "loss = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_mobilenet = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "    weights='imagenet')\n",
    "pretrained_mobilenet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = keras.layers.Dense(1)\n",
    "\n",
    "mnet_model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_pooling_layer,\n",
    "  prediction_layer])\n",
    "\n",
    "mnet_model.compile(optimizer=RMSprop(lr=learning_rate),\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "mnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnet_history = mnet_model.fit_generator(\n",
    "        train_augmented_generator, \n",
    "        steps_per_epoch=int(total_train_samples/batch_size),  \n",
    "        epochs=n_epochs,\n",
    "        verbose=1,\n",
    "        validation_data=vdate_datagen\n",
    "        validation_steps=int(total_vdate_samples/batch_size),\n",
    "        use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
