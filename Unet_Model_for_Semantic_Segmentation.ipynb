{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet Model for Semantic Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y5Eyt_8WTMg",
        "colab_type": "text"
      },
      "source": [
        "# Using U-net style architecture for semantic segmentation\n",
        "I will train a u-net-style architecture on the labeled city dataset from "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27pX0dRKUlUq",
        "colab_type": "text"
      },
      "source": [
        "### Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQVzCt6XUjam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "target_size = (256,256)\n",
        "n_epochs = 25\n",
        "learning_rate = 0.000_001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_1OrbHAMN5k",
        "colab_type": "text"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RINwHYjearUG",
        "colab_type": "code",
        "outputId": "605aa491-5dc7-47d6-d69b-a8d03139fa91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# get colab status\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-qrlIDKa8x4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import (Dense, Conv2D, Flatten, Dropout, \n",
        "MaxPooling2D, BatchNormalization, Conv2DTranspose, concatenate, Input)\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence # to fix 'imagedatagenerator has no shape' error\n",
        "import os, zipfile, glob\n",
        "from math import ceil \n",
        "from PIL import Image\n",
        "from skimage import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg3xJNubNYXZ",
        "colab_type": "code",
        "outputId": "0da71be8-6c77-4a85-c67f-111017d391f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    os.chdir(r'/content/gdrive/My Drive/thinkful/colab_datasets/sidewalk_data/')\n",
        "else:\n",
        "    os.chdir(os.path.expanduser(r'~/Google Drive/thinkful/colab_datasets/sidewalk_data/'))\n",
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/thinkful/colab_datasets/sidewalk_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUZmgziJcCCv",
        "colab_type": "text"
      },
      "source": [
        "# Data Load\n",
        "### Cityscape Dataset\n",
        "This is a publically availible dataset from https://www.cityscapes-dataset.com/, though not downloadable without requesting a login which is granted based on email domain.\n",
        "Citation:  \n",
        ">Cvpr2016M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele, “The Cityscapes Dataset for Semantic Urban Scene Understanding,” in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016. [Bibtex]\n",
        "[main paper](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes.pdf) · [supplemental ](https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2016cityscapes-supplemental.pdf)· [arxiv](http://arxiv.org/abs/1604.01685) · [CVF](http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Cordts_The_Cityscapes_Dataset_CVPR_2016_paper.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmO_yxT5cBzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 0: # run once\n",
        "  os.chdir(r'/content/gdrive/My Drive/thinkful/colab_datasets/sidewalk_data/public_data/')\n",
        "  with zipfile.ZipFile(os.path.join(os.getcwd(), 'gtFine_trainvaltest.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./cityscape/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6fawQA4DC0e",
        "colab_type": "text"
      },
      "source": [
        "### downsample images and fix directory structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uo1u5iaDCUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize(path, destination):\n",
        "    '''\n",
        "    downsample images by 4x, \n",
        "    remove transparency layer, \n",
        "    save to flattened dir stuc\n",
        "    Args:\n",
        "        path = current directory\n",
        "        destination = destination for images\n",
        "    '''\n",
        "    dirs1 = np.array([os.path.join(path, x) for x in os.listdir(path)])\n",
        "    dirs = dirs1[[os.path.isdir(x) for x in dirs1]]\n",
        "    for direc in dirs:   # direc should be mask vs image folders\n",
        "        if not os.path.isdir(direc):\n",
        "            continue\n",
        "        subdirs = [os.path.join(direc, x) for x in os.listdir(direc)]\n",
        "        for subdir in subdirs:   # subdir should be train, val, test\n",
        "            subdirs2 = [os.path.join(subdir, x) for x in os.listdir(subdir)]\n",
        "            for subdir2 in subdirs2:   # subdir2 is city folders\n",
        "                items = os.listdir(subdir2)\n",
        "                for item in items:\n",
        "                    if not os.path.isfile(os.path.join(subdir2,item)):\n",
        "                        continue\n",
        "                    #skip json and noncolor masks\n",
        "                    if item.rfind('gtFine_color.png') == -1 and\\\n",
        "                    item.rfind('leftImg8bit.png') == -1:\n",
        "                        continue\n",
        "                    destin2 = os.path.join(destination, subdir[len(common_path)+1:])\n",
        "                    f, _ = os.path.splitext(item)\n",
        "                    if not os.path.exists(destin2):\n",
        "                        os.makedirs(destin2)\n",
        "                    destin3 = os.path.join(destin2, f+'_resized.png')\n",
        "                    \n",
        "                    im = Image.open(os.path.join(subdir2, item))\n",
        "                    if im.mode == \"RGBA\":\n",
        "                        im = im.convert('RGB')\n",
        "                    im = im.resize((512,256), Image.BICUBIC)\n",
        "                    im.save(destin3, format='PNG')\n",
        "                    im.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjQJpIMvdxud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#switch to cloud dir\n",
        "if IN_COLAB:\n",
        "    data_mount = r'/content/gdrive/My Drive/thinkful/colab_datasets/sidewalk_data/public_data/'  \n",
        "    destin = r'/content/gdrive/My Drive/thinkful/colab_datasets/sidewalk_data/public_data/cityscape_reduced/'\n",
        "else:\n",
        "    data_mount = os.path.expanduser(\n",
        "        r'~/Google Drive/thinkful/colab_datasets/sidewalk_data/public_data/')\n",
        "    destin = os.path.expanduser(\n",
        "        r\"~\\Documents\\GitHub\\sidewalks_deep-learning\\cityscape_reduced\")\n",
        "leftimages_path = os.path.join(data_mount, r'cityscape/leftImg8bit/') # no leading /\n",
        "mask_path = os.path.join(data_mount, r'cityscape/gtFine/')\n",
        "common_path = os.path.join(data_mount, r'cityscape')\n",
        "os.chdir(common_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeFhHYZnDy8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize(common_path, destin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkj0QI8NWybp",
        "colab_type": "text"
      },
      "source": [
        "### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QsDAxU1dZwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_locs(subset):    \n",
        "    '''grab name of every image \n",
        "    and store in dataframe with subset eg. train, test'''\n",
        "    df = pd.DataFrame(columns=['img_name', 'subset'])\n",
        "    if subset == 'img':\n",
        "        os.chdir(leftimages_path) # needed despite lack of reference to curpath\n",
        "        img_paths = os.listdir(leftimages_path)\n",
        "        search_for = '*/*'\n",
        "    elif subset == 'mask': \n",
        "        os.chdir(mask_path)\n",
        "        img_paths = os.listdir(mask_path)   \n",
        "        search_for = '*/*_gtFine_color.png'\n",
        "    else:\n",
        "        raise NameError(\"subset should be 'img' or 'mask'\")\n",
        "    for subsetdir in img_paths:\n",
        "        img_files = [x[len(subsetdir)+1:] for x in glob.glob(os.path.join(subsetdir, search_for))]\n",
        "        img_files_s = pd.Series(img_files)\n",
        "        new_df = None\n",
        "        new_df = pd.DataFrame(columns=['img_name', 'subset'])\n",
        "        new_df['img_name'] = img_files_s\n",
        "        new_df['subset'].fillna(subsetdir, inplace=True)\n",
        "        df = df.append(new_df)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkAAKtaSQTMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_name(name):\n",
        "  '''removes _gtFine_color.png or _leftImg8bit.png'''\n",
        "  which = name.rfind('_leftImg8bit.png')\n",
        "  if which == -1:\n",
        "    which = '_gtFine_color.png'\n",
        "  else:\n",
        "    which =  '_leftImg8bit.png'\n",
        "  loc=name.rfind(which)\n",
        "  return name[:loc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArIMjgFz-uz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = get_image_locs('img')\n",
        "mask_df = get_image_locs('mask')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Z2OCAgT7xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df['common_name'] = data_df.img_name.apply(clean_name)\n",
        "mask_df['common_name'] = mask_df.img_name.apply(clean_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSnp4W4JPmNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_full_df = None\n",
        "data_full_df = pd.merge(left=data_df, right=mask_df, \n",
        "                        how='inner', on='common_name',\n",
        "                        sort=False, \n",
        "                        suffixes=('_data', '_mask'))\\\n",
        "               [['img_name_data', 'subset_data', 'img_name_mask']]\n",
        "data_full_df.columns = ['img_name', 'subset_data', 'mask_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpvr4AWeWyIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImgLoadGenerator(Sequence):\n",
        "    \"\"\"\n",
        "    parent Sequence object generates data batches\n",
        "    \"\"\"\n",
        "    def __init__(self, data, batch_size, data_path, subset, widthxheight): \n",
        "        self.data = data[data.subset_data == subset]\n",
        "        self.data_path = data_path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_list = data.img_name.to_list()\n",
        "        self.mask_list = data.mask_name.to_list()\n",
        "        self.subset = subset\n",
        "        self.w_h = widthxheight\n",
        "       \n",
        "    def __len__(self):\n",
        "      \"\"\"last batch usually smaller\"\"\"\n",
        "      return int(np.ceil(len(self.image_list) / float(self.batch_size)))\n",
        "    def decode_img(self, file_path):\n",
        "        img = tf.io.read_file(file_path)\n",
        "        # convert the compressed string to a 3D uint8 tensor\n",
        "        img = tf.image.decode_png(img, channels=3)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)  # to [0,1] rng\n",
        "        return tf.image.resize(img, self.w_h)\n",
        "    def process_path(self, file_path):\n",
        "        # load the raw data from the file as a string\n",
        "\n",
        "        return img, label\n",
        "    def get_batch(self, idx, path_list, img_or_mask):\n",
        "        # Fetch a batch of images from a list of paths\n",
        "        if img_or_mask == 'img':\n",
        "            path_l = os.path.join(self.data_path, \"leftImg8bit\", self.subset)\n",
        "            col_slice = 0\n",
        "        else:\n",
        "            path_l = os.path.join(self.data_path, \"gtFine\", self.subset)\n",
        "            col_slice = 2\n",
        "        slice_start, slice_end = idx * self.batch_size, (1 + idx) * self.batch_size\n",
        "        im_set = self.data.iloc[slice_start:slice_end,col_slice].values\n",
        "        return np.array([self.decode_img(os.path.join(path_l, im)) for im in im_set])\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.get_batch(idx, self.image_list, 'img')\n",
        "        batch_y = self.get_batch(idx, self.mask_list, 'mask')\n",
        "        return batch_x, batch_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AzJ1S1Fbl-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_params = {'data':data_full_df,\n",
        "              'batch_size':8, \n",
        "              'data_path':common_path, \n",
        "              'widthxheight':target_size}\n",
        "train_generator = ImgLoadGenerator(subset='train', \n",
        "                                   **gen_params)\n",
        "vdate_generator = ImgLoadGenerator(subset='val',\n",
        "                                   **gen_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbuHBX8EXPwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "d45d0fa5-d9a8-43bd-d125-aaf31c865719"
      },
      "source": [
        "next(train_generator)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6be8f38d3987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'ImgLoadGenerator' object is not an iterator"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yinMtAVmKKIW",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-PcSznXcFG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aa8c3fa8-f3cf-48ea-990f-cff96e42f038"
      },
      "source": [
        "image_datagen = ImageDataGenerator(rescale=1./255)\n",
        "mask_datagen = ImageDataGenerator(rescale=1./255,)\n",
        "\n",
        "image_generator = image_datagen.flow_from_directory(\n",
        "    os.path.join(leftimages_path, 'train'),\n",
        "    class_mode=None)\n",
        "\n",
        "mask_generator = mask_datagen.flow_from_directory(\n",
        "    os.path.join(mask_path, 'val'),\n",
        "    class_mode=None)\n",
        "\n",
        "# combine generators into one which yields image and masks\n",
        "def combine_generator(gen1, gen2):\n",
        "    while True:\n",
        "        yield(next(gen1), next(gen2))\n",
        "\n",
        "train_generator_ffd = combine_generator(image_generator, mask_generator)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2975 images belonging to 18 classes.\n",
            "Found 1500 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZj1nOBdcGI-",
        "colab_type": "text"
      },
      "source": [
        "# Modeling\n",
        "I will build a basic U-net model, train it on the cityscape public dataset, and use that model & weights on the Denver dataset I have built. \n",
        "\n",
        "Model structure reference [here](http://cs230.stanford.edu/files_winter_2018/projects/6937642.pdf)\n",
        "\n",
        "Next, I will use the frozen weights from the first have of the model, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gynMScrP_TBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (*target_size, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Vg7YryWNue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use function for the blocks of the network\n",
        "def encoder_builder(input_, filters,\n",
        "                         activ='relu', kernel=(3,3), \n",
        "                         drop=.5, pad='same', kern_init='he_uniform'):\n",
        "  kwargs = {'filters': filters, 'activation': activ, 'kernel_size': kernel, \n",
        "       'padding': pad, 'kernel_initializer': kern_init}\n",
        "  x = Conv2D(**kwargs)(input_)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(drop)(x)\n",
        "  x = Conv2D(**kwargs)(x)\n",
        "  encoder = Dropout(drop)(x)\n",
        "  pooled = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(encoder)\n",
        "  return encoder, pooled\n",
        "\n",
        "def decoder_builder(input_, skip, filters, \n",
        "                    activ='relu', kernel=(2,2),\n",
        "                    drop=.5, pad='same', kern_init='he_uniform',\n",
        "                    ):\n",
        "  kwargs = {'filters': filters, 'activation': activ, 'kernel_size': kernel, \n",
        "       'padding': pad, 'kernel_initializer': kern_init} \n",
        "  x = Conv2DTranspose(**kwargs, strides=(2,2))(input_)\n",
        "  x = concatenate([x, skip], axis=-1)  # note axis is *-*1\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(drop)(x)\n",
        "  x = Conv2D(**kwargs)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(drop)(x)\n",
        "  x = Conv2D(**kwargs)(x)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqVLXyW3x94R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = Input(shape=img_shape)\n",
        "encoder1, pooled1 = encoder_builder(input_layer, filters=32)  # return (128x128x32)\n",
        "encoder2, pooled2 = encoder_builder(pooled1, filters=64)  # return (64x64x364)\n",
        "encoder3, pooled3 = encoder_builder(pooled2, filters=128)  # return (32x32x128)\n",
        "encoder4, pooled4 = encoder_builder(pooled3, filters=256)  # return (16x16x256)\n",
        "encoder5, pooled5 = encoder_builder(pooled4, filters=512)  # return (8x8x512)\n",
        "middle, middle_pool = encoder_builder(pooled5, filters=1024)  # return (4x4x1024)\n",
        "decoder512 = decoder_builder(middle, skip=encoder5, filters=512)\n",
        "decoder256 = decoder_builder(decoder512, skip=encoder4, filters=256)\n",
        "decoder128 = decoder_builder(decoder256, skip=encoder3, filters=128)\n",
        "decoder64 = decoder_builder(decoder128, skip=encoder2, filters=64)\n",
        "decoder32 = decoder_builder(decoder64, skip=encoder1, filters=32)\n",
        "out_layer = Conv2D(filters=1, kernel_size=(1, 1), \n",
        "                   activation='sigmoid')(decoder32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6xAW0lHDuCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet = models.Model(inputs=[input_layer], outputs=[out_layer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsRDy7X_EzUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet.compile(optimizer='adam', loss = tf.keras.losses.categorical_crossentropy, metrics = ['accuracy'])\n",
        "\n",
        "unet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWDSkQxsa-gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(unet, to_file='model.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xkq9hRUG_c9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh07lbaSTgEo",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNRLv-5pHLKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1ICDJMRUGj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = img_shape\n",
        "total_train_samples = data_full_df[data_full_df.subset_data == 'train'].shape[0]\n",
        "total_vdate_samples = data_full_df[data_full_df.subset_data == 'val'].shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LjVIpMzTiqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet_history = unet.fit_generator(\n",
        "    train_generator, \n",
        "    steps_per_epoch=int(total_train_samples/batch_size),\n",
        "    epochs=n_epochs,\n",
        "    verbose=1,\n",
        "    validation_data=vdate_generator,\n",
        "    validation_steps=int(total_vdate_samples/batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ehl03DJVTOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}